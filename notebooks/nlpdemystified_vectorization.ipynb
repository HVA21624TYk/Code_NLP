{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlpdemystified-vectorization.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HVA21624TYk/Code_NLP/blob/main/notebooks/nlpdemystified_vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F50G99nH112P"
      },
      "source": [
        "# Natural Language Processing Demystified | Simple Vectorization\n",
        "https://nlpdemystified.org<br>\n",
        "https://github.com/futuremojo/nlp-demystified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9x6fL6L3zsb"
      },
      "source": [
        "### spaCy upgrade and package installation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88uW0zDh4BkP"
      },
      "source": [
        "At the time this notebook was created, spaCy had newer releases but Colab was still using version 2.x by default. So the first step is to upgrade spaCy and download a statisical language model.\n",
        "<br><br>\n",
        "**IMPORTANT**<br>\n",
        "If you're running this in the cloud rather than using a local Jupyter server on your machine, then the notebook will **timeout** after a period of inactivity. If that happens and you don't reconnect in time, you will need to upgrade spaCy again and reinstall the requisite statistical packages.\n",
        "<br><br>\n",
        "Refer to this link on how to run Colab notebooks locally on your machine to avoid this issue:<br>\n",
        "https://research.google.com/colaboratory/local-runtimes.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THBGyQba4Bcm"
      },
      "source": [
        "!pip install -U spacy==3.*\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t81VT9JboTzt"
      },
      "source": [
        "# Basic Bag-of-Words (BOW)\n",
        "\n",
        "Course module for this demo: https://www.nlpdemystified.org/course/basic-bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "from scipy import spatial\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "u_EAof8njfHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1IVdG29wyJ7"
      },
      "source": [
        "## Plain frequency BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fwfWQDVyJpY"
      },
      "source": [
        "# A corpus of sentences.\n",
        "corpus = [\n",
        "  \"Red Bull drops hint on F1 engine.\",\n",
        "  \"Honda exits F1, leaving F1 partner Red Bull.\",\n",
        "  \"Hamilton eyes record eighth F1 title.\",\n",
        "  \"Aston Martin announces sponsor.\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILvS020Zzm6F"
      },
      "source": [
        "We want to build a basic bag-of-words (BOW) representation of our corpus. Based on what you now know from the lesson, you can probably do this from scratch using dictionaries and lists (and maybe that's a good exercise). Fortunately, there are robust libraries which make it easy.\n",
        "\n",
        "We can use the scikit-learn **CountVectorizer** which takes a collection of text documents and creates a matrix of token counts:<br>\n",
        "https://scikit-learn.org/stable/index.html<br>\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRhJPxbHwuj_"
      },
      "source": [
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAphZMVPBX9P"
      },
      "source": [
        "The *fit_transform* method does two things:\n",
        "1. It learns a vocabulary dictionary from the corpus.\n",
        "2. It returns a matrix where each row represents a document and each column represents a token (i.e. term).<br>\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5wi4_C7BAWv"
      },
      "source": [
        "bow = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3Bp1XNcF1FQ"
      },
      "source": [
        "We can take a look at the features and vocabulary dictionary. Notice the **CountVectorizer** took care of tokenization for us. It also removed punctuation and lower-cased everything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQbqvLgVF8B7"
      },
      "source": [
        "# View features (tokens).\n",
        "print(vectorizer.get_feature_names_out())\n",
        "\n",
        "# View vocabulary dictionary.\n",
        "vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dmNUkZeExam"
      },
      "source": [
        "Specifically, the **CountVectorizer** generates a sparse matrix using an efficient, compressed representation. The sparse matrix object includes a number of useful methods:\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lug2-xnAExsb"
      },
      "source": [
        "print(type(bow))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bywJ0XnGKPQ"
      },
      "source": [
        "If we look at the raw structure, we'll see tuples where the first element represents the document, and the second element represents a token ID. It's then followed by a count of that token. So in the second document (index 1), token 8 (\"f1\") occurs twice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At6Gt4bsEx2D"
      },
      "source": [
        "print(bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv1N1Io2EyAb"
      },
      "source": [
        "Before we explore further, we want to make a few modifications.\n",
        "1. What if we want to use another tokenizer like spaCy's?\n",
        "2. Instead of frequency, what if we want to have a binary BOW?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRgIHkzUVJtk"
      },
      "source": [
        "## Binary BOW with custom tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tof1PBgqEy1D"
      },
      "source": [
        "**CountVectorizer** supports using a custom tokenizer. For every document, it will call your tokenizer and expect a list of tokens returned. We'll create a simple callback below which has spaCy tokenize and filter tokens, and then return them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcCLawrWEzC7"
      },
      "source": [
        "# As usual, we start by importing spaCy and loading a statistical model.\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Create a tokenizer callback using spaCy under the hood. Here, we tokenize\n",
        "# the passed-in text and return the tokens, filtering out punctuation.\n",
        "def spacy_tokenizer(doc):\n",
        "  return [t.text for t in nlp(doc) if not t.is_punct]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drEe1Lv_OScv"
      },
      "source": [
        "This time, we instantiate **CountVectorizer** with our custom tokenizer (*spacy_tokenizer*), turn off case-folding, and also set the *binary* parameter to *True* so we simply get 1s and 0s marking token presence rather than token frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YREyWzaA-rT"
      },
      "source": [
        "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True)\n",
        "bow = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jDKQkZUOysa"
      },
      "source": [
        "Looking at the resulting feature names and vocabulary dictionary, we can see our *spacy_tokenizer* being used. If you're not convinced, you can remove the punctuation filtering in our tokenizer and rerun the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x6RBqTGq302"
      },
      "source": [
        "print(vectorizer.get_feature_names_out())\n",
        "vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFpQbdA-R3FI"
      },
      "source": [
        "To get a dense array representation of our sparse matrix, use *toarray*.<br>\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.toarray.html#scipy.sparse.csr_matrix.toarray\n",
        "\n",
        "We can also index and slice into the sparse matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yGr36aP9GCr"
      },
      "source": [
        "print('A dense representation like we saw in the slides.')\n",
        "print(bow.toarray())\n",
        "print()\n",
        "print('Indexing and slicing.')\n",
        "print(bow[0])\n",
        "print()\n",
        "print(bow[0:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF0NVhdEUR1r"
      },
      "source": [
        "## Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leI1VuDVVP4W"
      },
      "source": [
        "Writing your own cosine similarity function is straight-forward using numpy (left as an exercise). There are multiple ways to calculate it using scipy.\n",
        "<br><br>\n",
        "One way is using the **spatial** package, which is a collection of spatial algorithms and data structures. It has a method to calculate cosine *distance*. To get the cosine *similarity*, we have to substract the distance from 1.<br>\n",
        "https://docs.scipy.org/doc/scipy/reference/spatial.html<br>\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOQQ50IgXQfH"
      },
      "source": [
        "# The cosine method expects array_like inputs, so we need to generate\n",
        "# arrays from our sparse matrix.\n",
        "doc1_vs_doc2 = 1 - spatial.distance.cosine(bow[0].toarray()[0], bow[1].toarray()[0])\n",
        "doc1_vs_doc3 = 1 - spatial.distance.cosine(bow[0].toarray()[0], bow[2].toarray()[0])\n",
        "doc1_vs_doc4 = 1 - spatial.distance.cosine(bow[0].toarray()[0], bow[3].toarray()[0])\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "print(f\"Doc 1 vs Doc 2: {doc1_vs_doc2}\")\n",
        "print(f\"Doc 1 vs Doc 3: {doc1_vs_doc3}\")\n",
        "print(f\"Doc 1 vs Doc 4: {doc1_vs_doc4}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SRDwr2gYD04"
      },
      "source": [
        "Another approach is using scikit-learn's *cosine_similarity* which computes the metric between multiple vectors. Here, we pass it our BOW and get a matrix of cosine similarities between each document.<br>\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwwP8-jtchSI"
      },
      "source": [
        "# cosine_similarity can take either array-likes or sparse matrices.\n",
        "print(cosine_similarity(bow))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I96W6qDVdDnY"
      },
      "source": [
        "## N-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3E_hN5Ddyae"
      },
      "source": [
        "**CountVectorizer** includes an *ngram_range* parameter to generate different n-grams. n_gram range is specified using a minimum and maximum range. By default, n_gram range is set to (1, 1) which generates unigrams. Setting it to (1, 2) generates both unigrams and bigrams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZooyyRleHXe"
      },
      "source": [
        "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True, ngram_range=(1,2))\n",
        "bigrams = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print('Number of features: {}'.format(len(vectorizer.get_feature_names_out())))\n",
        "print(vectorizer.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvtmi3negc0G"
      },
      "source": [
        "# Setting n_gram range to (2, 2) generates only bigrams.\n",
        "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True, ngram_range=(2,2))\n",
        "bigrams = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(vectorizer.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7e40ZAKhQmm"
      },
      "source": [
        "## Basic Bag-of-Words Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbdMO0bZjROn"
      },
      "source": [
        "#\n",
        "# EXERCISE: Create a spacy_tokenizer callback which takes a string and returns\n",
        "# a list of tokens (each token's text) with punctuation filtered out.\n",
        "#\n",
        "corpus = [\n",
        "  \"Students use their GPS-enabled cellphones to take birdview photographs of a land in order to find specific danger points such as rubbish heaps.\",\n",
        "  \"Teenagers are enthusiastic about taking aerial photograph in order to study their neighbourhood.\",\n",
        "  \"Aerial photography is a great way to identify terrestrial features that aren’t visible from the ground level, such as lake contours or river paths.\",\n",
        "  \"During the early days of digital SLRs, Canon was pretty much the undisputed leader in CMOS image sensor technology.\",\n",
        "  \"Syrian President Bashar al-Assad tells the US it will 'pay the price' if it strikes against Syria.\"\n",
        "]\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def spacy_tokenizer(doc):\n",
        "  return [t.text for t in nlp(doc) if not t.is_punct]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjBJUUpcBWp2"
      },
      "source": [
        "#\n",
        "# EXERCISE: Initialize a CountVectorizer object and set it to use\n",
        "# your spacy_tokenizer with lower-casing off and to create a binary BOW.\n",
        "#\n",
        "\n",
        "# Instantiate a CountVectorizer object called 'vectorizer'.\n",
        "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True)\n",
        "\n",
        "# Create a binary BOW from the corpus using your CountVectorizer.\n",
        "bow = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print('A dense representation like we saw in the slides.')\n",
        "print(bow.toarray())\n",
        "print('Indexing and slicing.')\n",
        "print(bow[0])\n",
        "print(\"=\"*30)\n",
        "print(bow[0:2])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.vocabulary_"
      ],
      "metadata": {
        "id": "4kFoL5Gmin3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os3tPj5nmRLw"
      },
      "source": [
        "#\n",
        "# The string below is a whole paragraph. We want to create another\n",
        "# binary BOW but using the vocabulary of our *current* CountVectorizer. This means\n",
        "# that words in this paragraph which AREN'T already in the vocabulary won't be\n",
        "# represented. This is to illustrate how BOW can't handle out-of-vocabulary words\n",
        "# unless you rebuild your whole vocabulary. Still, we'll see that if there's\n",
        "# enough overlapping vocabulary, some similarity can still be picked up.\n",
        "#\n",
        "# Note that we call 'transform' only instead of 'fit_transform' because the\n",
        "# fit step (i.e. vocabulary build) is already done and we don't want to re-fit here.\n",
        "#\n",
        "s = [\"Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\"]\n",
        "new_bow = vectorizer.transform(s)\n",
        "\n",
        "#\n",
        "# EXERCISE: using the pairwise cosine_similarity method from sklearn,\n",
        "# calculate the similarities between each document from the corpus against\n",
        "# this new document (new_bow). HINT: You can pass two parameters to\n",
        "# cosine_similarity in this case. See the docs:\n",
        "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n",
        "#\n",
        "# Which document is the most similar? Which is the least similar? Do the results make sense\n",
        "# based on what you see?\n",
        "#\n",
        "\n",
        "similar = cosine_similarity(bow, new_bow)\n",
        "# for t, sim in enumerate(similar.flatten()):\n",
        "#   print(f\"Doc {t}: {sim:.4f}\")\n",
        "print(similar)\n",
        "\n",
        "most_similar = similar.argmax()\n",
        "print(f\"Most similar: {corpus[most_similar]}\")\n",
        "least_similar = similar.argmin()\n",
        "print(f\"Least similar: {corpus[least_similar]}\")\n",
        "\n",
        "print(f\"\\nDocument tương đồng nhất: {most_similar} (score: {similar.max():.4f})\")\n",
        "print(f\"Document ít tương đồng nhất: {least_similar} (score: {similar.min():.4f})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXThYmDiwMmR"
      },
      "source": [
        "#\n",
        "# EXERCISE: Implement your own cosine similarity method using numpy.\n",
        "# It should take two numpy arrays and output the similarity metric.\n",
        "# HINTS:\n",
        "# https://numpy.org/doc/stable/reference/generated/numpy.dot.html\n",
        "# https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n",
        "#\n",
        "# Verify the similarity between the first document in the corpus and the\n",
        "# paragraph is the same as the one you got from using pairwise cosine_similarity.\n",
        "#\n",
        "import numpy as np\n",
        "def cos_sim(a, b):\n",
        "  dot_product = np.dot(a,b)\n",
        "  norm_a = np.linalg.norm(a)\n",
        "  norm_b = np.linalg.norm(b)\n",
        "  if norm_a == 0 and norm_b == 0:\n",
        "    return 0\n",
        "  return dot_product / (norm_a * norm_b)\n",
        "\n",
        "\n",
        "doc1 = bow.toarray()[0].flatten()\n",
        "paragraph = new_bow.toarray().flatten()\n",
        "manual_similarity = cos_sim(doc1, paragraph)\n",
        "print(cos_sim(doc1, paragraph))\n",
        "sklearn_similarity = cosine_similarity(bow[0], paragraph.reshape(1, -1))[0][0]\n",
        "print(f\"Manual implementation: {manual_similarity:.6f}\")\n",
        "print(f\"Sklearn implementation: {sklearn_similarity:.6f}\")\n",
        "print(f\"Difference: {abs(manual_similarity - sklearn_similarity):.10f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghlqn6l-dal4"
      },
      "source": [
        "#\n",
        "# EXERCISE: In spacy_tokenizer, instead of returning the plain text,\n",
        "# return the lemma_ attribute instead. How do the cosine similarity\n",
        "# results differ? What if you filter out stop words as well?\n",
        "#\n",
        "\n",
        "def lemma_tokenizer(doc):\n",
        "  return [t.lemma_ for t in nlp(doc) if not t.is_punct]\n",
        "\n",
        "def lemma_stopword_tokenizer(doc):\n",
        "  return [t.lemma_ for t in nlp(doc) if not t.is_punct and not t.is_stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer1 = CountVectorizer(tokenizer=lemma_tokenizer, lowercase=False, binary=True)\n",
        "bow1 = vectorizer1.fit_transform(corpus)\n",
        "vectorizer1.vocabulary_"
      ],
      "metadata": {
        "id": "XMkE3CwMiznq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vectorizer2 = CountVectorizer(tokenizer=lemma_stopword_tokenizer, lowercase=False, binary=True)\n",
        "bow2 = vectorizer2.fit_transform(corpus)\n",
        "vectorizer2.vocabulary_"
      ],
      "metadata": {
        "id": "EKV1yVUwi12K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def cos_sim(a, b):\n",
        "  dot_product = np.dot(a,b)\n",
        "  norm_a = np.linalg.norm(a)\n",
        "  norm_b = np.linalg.norm(b)\n",
        "  if norm_a == 0 and norm_b == 0:\n",
        "    return 0\n",
        "  return dot_product / (norm_a * norm_b)\n",
        "\n",
        "\n",
        "doc1 = bow1.toarray()[0].flatten()\n",
        "paragraph = vectorizer1.transform(s).toarray().flatten()\n",
        "manual_similarity = cos_sim(doc1, paragraph)\n",
        "# print(cos_sim(doc1, paragraph))\n",
        "sklearn_similarity = cosine_similarity(bow1[0], paragraph.reshape(1, -1))[0][0]\n",
        "print(f\"Manual implementation: {manual_similarity:.6f}\")\n",
        "print(f\"Sklearn implementation: {sklearn_similarity:.6f}\")\n",
        "print(f\"Difference: {abs(manual_similarity - sklearn_similarity):.10f}\")"
      ],
      "metadata": {
        "id": "TJQSOiWSi4Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def cos_sim(a, b):\n",
        "  dot_product = np.dot(a,b)\n",
        "  norm_a = np.linalg.norm(a)\n",
        "  norm_b = np.linalg.norm(b)\n",
        "  if norm_a == 0 and norm_b == 0:\n",
        "    return 0\n",
        "  return dot_product / (norm_a * norm_b)\n",
        "\n",
        "\n",
        "doc1 = bow2.toarray()[0].flatten()\n",
        "paragraph = vectorizer2.transform(s).toarray().flatten()\n",
        "manual_similarity = cos_sim(doc1, paragraph)\n",
        "print(cos_sim(doc1, paragraph))\n",
        "sklearn_similarity = cosine_similarity(bow2[0], paragraph.reshape(1, -1))[0][0]\n",
        "print(f\"Manual implementation: {manual_similarity:.6f}\")\n",
        "print(f\"Sklearn implementation: {sklearn_similarity:.6f}\")\n",
        "print(f\"Difference: {abs(manual_similarity - sklearn_similarity):.10f}\")"
      ],
      "metadata": {
        "id": "7PEJjZ9Ei9ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnC_i4oH2ARW"
      },
      "source": [
        "# TF-IDF\n",
        "\n",
        "Course module for this demo: https://www.nlpdemystified.org/course/tf-idf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE: If the notebook timed out, you may need to re-upgrade spaCy and re-install the language model as follows:**"
      ],
      "metadata": {
        "id": "Xb7W_O_FS3H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy==3.*\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy info"
      ],
      "metadata": {
        "id": "rRtp9F8KS5QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "CMwv39AfP7Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmcTBtSx-XqZ"
      },
      "source": [
        "## Fetching datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYkq3i7_-qhQ"
      },
      "source": [
        "This time around, rather than using a short toy corpus, let's use a larger dataset. scikit-learn has a **datasets** module with utilties to load datasets of our own as well as fetch popular reference datasets online.<br>\n",
        "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n",
        "<br><br>\n",
        "We'll use the **20 newsgroups** dataset, which is a collection of 18,000 newsgroup posts across 20 topics.<br>\n",
        "https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset\n",
        "<br><br>\n",
        "List of datasets available:<br>\n",
        "https://scikit-learn.org/stable/datasets.html#datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYjxqxVBBINV"
      },
      "source": [
        "The **datasets** module includes fetchers for each dataset in scikit-learn. For our purposes, we'll fetch only the posts from the *sci.space* topic, and skip on headers, footers, and quoting of other posts.<br>\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups\n",
        "<br><br>\n",
        "By default, the fetcher retrieves the *training* subset of the data only. If you don't know what that means, it'll become clear later in the course when we discuss modelling. For now, it doesn't matter for our purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9to6gQNCGiN"
      },
      "source": [
        "corpus = fetch_20newsgroups(categories=['sci.space'],\n",
        "                            remove=('headers', 'footers', 'quotes'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W989GHQxDvTW"
      },
      "source": [
        "We get back a **Bunch** container object containing the data as well as other information.<br>\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html\n",
        "<br><br>\n",
        "The actual posts are accessed through the *data* attribute and is a list of strings, each one representing a post."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POGdVmdIDuCK"
      },
      "source": [
        "print(type(corpus))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6AgmbL0ES9I"
      },
      "source": [
        "# Number of posts in our dataset.\n",
        "len(corpus.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAjM4uNDEXGf"
      },
      "source": [
        "# View first two posts.\n",
        "corpus.data[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH99M6cxCpsz"
      },
      "source": [
        "## Creating TF-IDF features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtnQX-wWDhGh"
      },
      "source": [
        "# Like before, if we want to use spaCy's tokenizer, we need\n",
        "# to create a callback. Remember to upgrade spaCy if you need\n",
        "# to (refer to beginnning of file for commentary and instructions).\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# We don't need named-entity recognition nor dependency parsing for\n",
        "# this so these components are disabled. This will speed up the\n",
        "# pipeline. We do need part-of-speech tagging however.\n",
        "unwanted_pipes = [\"ner\", \"parser\"]\n",
        "\n",
        "# For this exercise, we'll remove punctuation and spaces (which\n",
        "# includes newlines), filter for tokens consisting of alphabetic\n",
        "# characters, and return the lemma (which require POS tagging).\n",
        "def spacy_tokenizer(doc):\n",
        "  with nlp.disable_pipes(*unwanted_pipes):\n",
        "    return [t.lemma_ for t in nlp(doc) if \\\n",
        "            not t.is_punct and \\\n",
        "            not t.is_space and \\\n",
        "            t.is_alpha]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il-0gY9LEiNv"
      },
      "source": [
        "Like the classes to create raw frequency and binary bag-of-words vectors, scikit-learn includes a similar class called **TfidfVectorizer** to create TF-IDF vectors from a corpus.<br>\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "<br><br>\n",
        "The usage pattern is similar in that we call *fit_transform* on the corpus which generates the vocabulary dictionary (fit step), and generates the TF-IDF vectors (transform step)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shj6BS0BN6FU"
      },
      "source": [
        "%%time\n",
        "# Use the default settings of TfidfVectorizer.\n",
        "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
        "features = vectorizer.fit_transform(corpus.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ9w4gh9sobB"
      },
      "source": [
        "# The number of unique tokens.\n",
        "print(len(vectorizer.get_feature_names_out()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CxmKlPcNRLk"
      },
      "source": [
        "# The dimensions of our feature matrix. X rows (documents) by Y columns (tokens).\n",
        "print(features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJwnU8PZNdHU"
      },
      "source": [
        "# What the encoding of the first document looks like in sparse format.\n",
        "print(features[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp7VTwYzONlt"
      },
      "source": [
        "As we mentioned in the slides, there are TF-IDF variations out there and scikit-learn, among other things, adds **smoothing** (adds a one to the numerator and denominator in the IDF component), and normalizes by default. These can be disabled if desired using the *smooth_idf* and *norm* parameters respectively. See here for more information:<br>\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylKLM-IMOwbJ"
      },
      "source": [
        "## Querying the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8oTtCg0QB71"
      },
      "source": [
        "The similarity measuring techniques we learned previously can be used here in the same way. In effect, we can query our data using this sequence:\n",
        "1. *Transform* our query using the same vocabulary from our *fit* step on our corpus.\n",
        "2. Calculate the pairwise cosine similarities between each document in our corpus and our query.\n",
        "3. Sort them in descending order by score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNjEUzqlP6Oy"
      },
      "source": [
        "# Transform the query into a TF-IDF vector.\n",
        "query = [\"lunar orbit\"]\n",
        "query_tfidf = vectorizer.transform(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEfdfkmpP8Tv"
      },
      "source": [
        "# Calculate the cosine similarities between the query and each document.\n",
        "# We're calling flatten() here becaue cosine_similarity returns a list\n",
        "# of lists and we just want a single list.\n",
        "cosine_similarities = cosine_similarity(features, query_tfidf).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skuSFhLxXOMC"
      },
      "source": [
        "Now that we have our list of cosine similarities, we can use this utility function to return the indices of the top k documents with the highest cosine similarities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0PvqRDpUSYO"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# numpy's argsort() method returns a list of *indices* that\n",
        "# would sort an array:\n",
        "# https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
        "#\n",
        "# The sort is ascending, but we want the largest k cosine_similarites\n",
        "# at the bottom of the sort. So we negate k, and get the last k\n",
        "# entries of the indices list in reverse order. There are faster\n",
        "# ways to do this using things like argpartition but this is\n",
        "# more succinct.\n",
        "def top_k(arr, k):\n",
        "  kth_largest = (k + 1) * -1\n",
        "  return np.argsort(arr)[:kth_largest:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFYpEldVUaAG"
      },
      "source": [
        "# So for our query above, these are the top five documents.\n",
        "top_related_indices = top_k(cosine_similarities, 5)\n",
        "print(top_related_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e86P3bQR1ZS"
      },
      "source": [
        "# Let's take a look at their respective cosine similarities.\n",
        "print(cosine_similarities[top_related_indices])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzdyTptURiTQ"
      },
      "source": [
        "# Top match.\n",
        "print(corpus.data[top_related_indices[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQwWXypfR8vh"
      },
      "source": [
        "# Second-best match.\n",
        "print(corpus.data[top_related_indices[1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-5aqUbGSM5J"
      },
      "source": [
        "# Try a different query\n",
        "query = [\"satellite\"]\n",
        "query_tfidf = vectorizer.transform(query)\n",
        "\n",
        "cosine_similarities = cosine_similarity(features, query_tfidf).flatten()\n",
        "top_related_indices = top_k(cosine_similarities, 5)\n",
        "\n",
        "print(top_related_indices)\n",
        "print(cosine_similarities[top_related_indices])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHQtRQIcSbTj"
      },
      "source": [
        "print(corpus.data[top_related_indices[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4v5wQ4JaBIh"
      },
      "source": [
        "So here we have the beginnings of a simple search engine but we're a far cry from competing with commercial off-the-shelf search engines, let alone Google.\n",
        "<br>\n",
        "- For each query, we're scanning through our entire corpus, but in practice, you'll want to create an **inverted index**. Search applications such as Elasticsearch do that under the hood.\n",
        "- You'd also want to evaluate the efficacy of your search using metrics like **precision** and **recall**.\n",
        "- Document ranking also tends to be more sophisticated, using different ranking functions like Okapi BM25. With major search engines, ranking also involves hundreds of variables such as what the user searched for previously, what do they tend to click on, where are they physically, and on and on. These variables are part of the \"secret sauce\" and are closely guarded by companies.\n",
        "- Beyond word presence, intent and meaning are playing a larger role.\n",
        "<br>\n",
        "\n",
        "Information Retrieval is a huge, rich topic and beyond search, it's also key in tasks such as question-answering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak3LXiETfGIY"
      },
      "source": [
        "## TF-IDF Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08nTQB7_fJU0"
      },
      "source": [
        "**EXERCISE**<br>\n",
        "Read up on these concepts we just mentioned if you're curious.<br>\n",
        "\n",
        "https://en.wikipedia.org/wiki/Inverted_index<br>\n",
        "https://en.wikipedia.org/wiki/Precision_and_recall<br>\n",
        "https://en.wikipedia.org/wiki/Okapi_BM25<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz2FCCq1fsjz"
      },
      "source": [
        "#\n",
        "# EXERCISE: fetch multiple topics from the 20 newsgroups\n",
        "# dataset and query them using the approach we followed.\n",
        "# A list of topics can be found here:\n",
        "# https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset\n",
        "#\n",
        "# If you're feeling ambitious, incorporate n-grams or\n",
        "# look at how you can measure precision and recall.\n",
        "#\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = fetch_20newsgroups(categories=['sci.crypt', 'alt.atheism', 'comp.sys.ibm.pc.hardware'], remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "pwc8HhDBqbC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.target_names"
      ],
      "metadata": {
        "id": "rnev-caaqyzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.data[:5]"
      ],
      "metadata": {
        "id": "B2YVqjCQrTNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(corpus))"
      ],
      "metadata": {
        "id": "7mGj_I4ur21b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus.data)"
      ],
      "metadata": {
        "id": "s6DDN90EsQ5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "unwanted_pipes = [\"ner\", \"parser\"]\n",
        "\n",
        "def spacy_tokenizer(doc):\n",
        "  with nlp.disable_pipes(*unwanted_pipes):\n",
        "    return [t.lemma_ for t in nlp(doc) if \\\n",
        "            not t.is_punct and \\\n",
        "            not t.is_space and\\\n",
        "            t.is_alpha]"
      ],
      "metadata": {
        "id": "nw1A1CYwsWND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
        "feature = vectorizer.fit_transform(corpus.data)"
      ],
      "metadata": {
        "id": "myRZ2K4Du0IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vectorizer.get_feature_names_out()))"
      ],
      "metadata": {
        "id": "8DDK0w2zwQ-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature.shape)"
      ],
      "metadata": {
        "id": "vGzS-V-mwupV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature[0])"
      ],
      "metadata": {
        "id": "5xpNAvsJw3KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = [\"I think\"]\n",
        "query_tfidf = vectorizer.transform(query)"
      ],
      "metadata": {
        "id": "46XFGA-rxOdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarities = cosine_similarity(feature, query_tfidf).flatten()"
      ],
      "metadata": {
        "id": "ewfA-ZPlxuNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k(arr, k):\n",
        "  kth_largest = (k + 1) * -1\n",
        "  return np.argsort(arr)[:kth_largest :-1]\n",
        "\n"
      ],
      "metadata": {
        "id": "pdpJurIkx7uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_related_indices = top_k(cosine_similarities, 5)\n",
        "print(top_related_indices)"
      ],
      "metadata": {
        "id": "wYiHRE2nyiR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarities[top_related_indices])"
      ],
      "metadata": {
        "id": "ChMn4zlWyuPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus.data[top_related_indices[0]])"
      ],
      "metadata": {
        "id": "yIYIdjYcyvBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus.data[top_related_indices[1]])"
      ],
      "metadata": {
        "id": "XjprF9yPzNQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query = [\"Experiment\"]\n",
        "query_tfidf = vectorizer.transform(query)\n",
        "cosine_similarities = cosine_similarity(feature, query_tfidf).flatten()\n",
        "top_related_indices = top_k(cosine_similarities, 5)\n",
        "print(top_related_indices)\n",
        "print(cosine_similarities[top_related_indices])"
      ],
      "metadata": {
        "id": "p9MsRoY6zYAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus.data[top_related_indices[0]])"
      ],
      "metadata": {
        "id": "GD2YVtXbzrF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus.data[top_related_indices[1]])"
      ],
      "metadata": {
        "id": "xTpJrUGJ0OGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus.data[top_related_indices[2]])"
      ],
      "metadata": {
        "id": "7LXxX8aI0b5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78585d88"
      },
      "source": [
        "# Task\n",
        "Evaluate the search engine's performance using Precision, Recall, and F1-score for a given query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f06458f4"
      },
      "source": [
        "## Define relevant documents\n",
        "\n",
        "### Subtask:\n",
        "For a given query, manually identify which documents in the corpus are relevant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1783481b"
      },
      "source": [
        "**Reasoning**:\n",
        "Choose a query and manually identify relevant documents by iterating through the corpus and checking for keywords or themes related to the query.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "630467ff"
      },
      "source": [
        "# Choose a query string\n",
        "query_string = \"encryption\"\n",
        "\n",
        "# Manually identify relevant documents based on the query.\n",
        "# This is a subjective step based on reading the content.\n",
        "# We are looking for documents discussing encryption, cryptography, keys, security, etc.\n",
        "relevant_indices = []\n",
        "for i, doc in enumerate(corpus.data):\n",
        "    # Simple check for keywords related to the query \"encryption\"\n",
        "    # This is a manual and subjective process\n",
        "    if \"encrypt\" in doc.lower() or \"cryptography\" in doc.lower() or \"key\" in doc.lower() or \"security\" in doc.lower():\n",
        "        relevant_indices.append(i)\n",
        "\n",
        "print(f\"Query: '{query_string}'\")\n",
        "print(f\"Number of manually identified relevant documents: {len(relevant_indices)}\")\n",
        "# print(f\"Indices of relevant documents: {relevant_indices}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bfdcea2"
      },
      "source": [
        "## Perform a search\n",
        "\n",
        "### Subtask:\n",
        "Use the current TF-IDF vectorizer and cosine similarity to get a ranked list of documents for the query.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b05c27c"
      },
      "source": [
        "**Reasoning**:\n",
        "Transform the query into a TF-IDF vector and calculate cosine similarities with the corpus features. Then, get the top k document indices based on these similarities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e6d3ddf"
      },
      "source": [
        "query = [query_string]\n",
        "query_tfidf = vectorizer.transform(query)\n",
        "\n",
        "cosine_similarities = cosine_similarity(feature, query_tfidf).flatten()\n",
        "\n",
        "# Choose k, for example, 20\n",
        "k = 20\n",
        "top_related_indices = top_k(cosine_similarities, k)\n",
        "\n",
        "print(f\"Top {k} document indices based on cosine similarity:\")\n",
        "print(top_related_indices)\n",
        "print(\"\\nCosine similarities for the top documents:\")\n",
        "print(cosine_similarities[top_related_indices])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "018d2b31"
      },
      "source": [
        "## Calculate precision\n",
        "\n",
        "### Subtask:\n",
        "Calculate the precision at a given cutoff (e.g., top 5 or 10 documents). Precision is the fraction of retrieved documents that are relevant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c8f5cfe"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the precision at the specified cutoff by iterating through the top documents and checking if they are in the list of relevant documents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f72d4fd3"
      },
      "source": [
        "# Define the cutoff value (number of top documents to consider)\n",
        "cutoff = 20\n",
        "\n",
        "# Get the indices of the top documents up to the cutoff\n",
        "top_docs_at_cutoff = top_related_indices[:cutoff]\n",
        "\n",
        "# Initialize a counter for relevant documents found in the top documents\n",
        "relevant_docs_in_top_k = 0\n",
        "\n",
        "# Iterate through the top documents and check for relevance\n",
        "for doc_index in top_docs_at_cutoff:\n",
        "  if doc_index in relevant_indices:\n",
        "    relevant_docs_in_top_k += 1\n",
        "\n",
        "# Calculate precision\n",
        "precision = relevant_docs_in_top_k / cutoff\n",
        "\n",
        "# Print the calculated precision\n",
        "print(f\"Precision at cutoff {cutoff}: {precision:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f955a44"
      },
      "source": [
        "## Calculate recall\n",
        "\n",
        "### Subtask:\n",
        "Calculate the recall at a given cutoff. Recall is the fraction of relevant documents that are retrieved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d1a1e65"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the total number of relevant documents and then calculate the recall at the specified cutoff.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41ab1155"
      },
      "source": [
        "# Calculate the total number of relevant documents in the corpus\n",
        "total_relevant_documents = len(relevant_indices)\n",
        "\n",
        "# Calculate recall\n",
        "recall = relevant_docs_in_top_k / total_relevant_documents\n",
        "\n",
        "# Print the calculated recall\n",
        "print(f\"Recall at cutoff {cutoff}: {recall:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fa01319"
      },
      "source": [
        "## Calculate f1-score\n",
        "\n",
        "### Subtask:\n",
        "Calculate the F1-score, which is the harmonic mean of precision and recall.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61f5eab6"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the F1-score using the precision and recall values, handling the case where both are zero to avoid division by zero, and print the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e697811"
      },
      "source": [
        "# Calculate F1-score\n",
        "if precision + recall == 0:\n",
        "  f1_score = 0.0\n",
        "else:\n",
        "  f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Print the F1-score\n",
        "print(f\"F1-score at cutoff {cutoff}: {f1_score:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52203c07"
      },
      "source": [
        "## Interpret results\n",
        "\n",
        "### Subtask:\n",
        "Discuss the calculated metrics and what they indicate about the search engine's performance for the given query.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90348324"
      },
      "source": [
        "**Reasoning**:\n",
        "Discuss the calculated precision, recall, and F1-score values in the context of search engine evaluation and the TF-IDF model's performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bb8cf6f"
      },
      "source": [
        "print(f\"Precision at cutoff {cutoff}: {precision:.4f}\")\n",
        "print(f\"Recall at cutoff {cutoff}: {recall:.4f}\")\n",
        "print(f\"F1-score at cutoff {cutoff}: {f1_score:.4f}\")\n",
        "\n",
        "print(\"\\nAnalysis of Search Engine Performance (Query: 'encryption')\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"Precision ({precision:.4f}): Of the {cutoff} documents retrieved, {relevant_docs_in_top_k} were identified as relevant.\")\n",
        "print(\"A precision of 1.0000 indicates that every document in the top 20 results was relevant according to our manual identification.\")\n",
        "\n",
        "print(f\"\\nRecall ({recall:.4f}): The search engine retrieved {relevant_docs_in_top_k} out of a total of {total_relevant_documents} relevant documents in the corpus.\")\n",
        "print(\"A low recall of 0.0513 suggests that while the documents retrieved were relevant, a large number of relevant documents in the corpus were not found within the top 20 results.\")\n",
        "\n",
        "print(f\"\\nF1-score ({f1_score:.4f}): The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both.\")\n",
        "print(\"A low F1-score of 0.0976 indicates that despite perfect precision in the top 20, the overall performance is limited by the low recall.\")\n",
        "\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"For the query 'encryption', the search engine achieved perfect precision within the top 20 results, meaning all retrieved documents were relevant.\")\n",
        "print(\"However, the recall is very low, indicating that the search engine only found a small fraction of the total relevant documents in the corpus.\")\n",
        "print(\"This suggests that the ranking is effective at placing some relevant documents highly, but it misses many others.\")\n",
        "print(\"The low recall could be attributed to several factors, including:\")\n",
        "print(\"- The simplicity of the TF-IDF model, which might not capture complex semantic relationships or synonyms effectively.\")\n",
        "print(\"- The manual and potentially limited definition of relevant documents used for evaluation.\")\n",
        "print(\"- The inherent difficulty of the query and the diversity of how 'encryption' might be discussed in the corpus.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28733cde"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   For the query \"encryption\", 390 documents were manually identified as relevant in the corpus.\n",
        "*   Using a TF-IDF vectorizer and cosine similarity, the search engine retrieved a ranked list of documents.\n",
        "*   At a cutoff of 20 documents, the search engine achieved a Precision of 1.0000, meaning all 20 retrieved documents were among those manually identified as relevant.\n",
        "*   At the same cutoff of 20, the Recall was 0.0513, indicating that only a small fraction (20 out of 390) of the total relevant documents were retrieved within the top 20 results.\n",
        "*   The F1-score, which balances precision and recall, was calculated as 0.0976 at the cutoff of 20.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The search engine is effective at ranking some relevant documents highly (perfect precision in the top 20), but it fails to retrieve a large proportion of the total relevant documents in the corpus (very low recall).\n",
        "*   Future steps could involve exploring more advanced search models (beyond simple TF-IDF) or refining the definition and identification of relevant documents to improve recall and overall F1-score.\n"
      ]
    }
  ]
}